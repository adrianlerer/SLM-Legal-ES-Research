# SCM Legal Training Framework
## Small Concept Models for Legal Domain - Training Implementation

Esta carpeta contiene la implementaci√≥n completa del framework de entrenamiento para SCM Legal, dise√±ado para la investigaci√≥n acad√©mica y publicaci√≥n de papers.

## üöÄ Visi√≥n General

El framework SCM Legal implementa **Small Concept Models** especializados para el dominio legal, con capacidades avanzadas de:

- **Razonamiento Conceptual**: Operaciones a nivel de concepto en lugar de tokens
- **Extracci√≥n de Conceptos Legales**: Identificaci√≥n autom√°tica de conceptos jur√≠dicos
- **Cadenas de Razonamiento**: Generaci√≥n de inferencias legales multi-paso
- **Multi-jurisdiccional**: Soporte para Argentina, Chile, Uruguay y Espa√±a
- **Evaluaci√≥n Acad√©mica**: M√©tricas especializadas para investigaci√≥n

## üìÅ Estructura del Proyecto

```
training/
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îî‚îÄ‚îÄ scm_training_config.yaml      # Configuraci√≥n completa del entrenamiento
‚îú‚îÄ‚îÄ data/                             # Datos generados autom√°ticamente
‚îÇ   ‚îú‚îÄ‚îÄ legal_corpus_train.jsonl      # Dataset de entrenamiento
‚îÇ   ‚îú‚îÄ‚îÄ legal_corpus_validation.jsonl # Dataset de validaci√≥n  
‚îÇ   ‚îî‚îÄ‚îÄ legal_corpus_test.jsonl       # Dataset de prueba
‚îú‚îÄ‚îÄ results/                          # Resultados de entrenamiento y evaluaci√≥n
‚îú‚îÄ‚îÄ logs/                            # Logs de entrenamiento
‚îú‚îÄ‚îÄ checkpoints/                     # Checkpoints del modelo
‚îú‚îÄ‚îÄ concept_extractor.py             # Extractor de conceptos legales avanzado
‚îú‚îÄ‚îÄ concept_reasoner.py              # Motor de razonamiento conceptual
‚îú‚îÄ‚îÄ evaluation_metrics.py            # M√©tricas de evaluaci√≥n especializadas
‚îú‚îÄ‚îÄ data_preparation.py              # Pipeline de preparaci√≥n de datos
‚îú‚îÄ‚îÄ scm_trainer.py                   # Entrenador principal del modelo
‚îú‚îÄ‚îÄ train_scm_legal.py              # Script principal de entrenamiento
‚îú‚îÄ‚îÄ requirements-training.txt        # Dependencias para entrenamiento
‚îî‚îÄ‚îÄ README.md                       # Esta documentaci√≥n
```

## üîß Instalaci√≥n y Configuraci√≥n

### Requisitos del Sistema

- **GPU**: NVIDIA GPU con al menos 8GB VRAM (16GB+ recomendado)
- **RAM**: M√≠nimo 16GB, recomendado 32GB+
- **Storage**: 50GB+ espacio libre
- **Python**: 3.8+ (recomendado 3.10)

### Instalaci√≥n de Dependencias

```bash
# Crear entorno virtual
python -m venv scm_legal_env
source scm_legal_env/bin/activate  # Linux/Mac
# scm_legal_env\Scripts\activate   # Windows

# Instalar dependencias
pip install -r requirements-training.txt

# Instalar modelos de SpaCy
python -m spacy download es_core_news_lg
python -m spacy download es_core_news_sm
```

### Configuraci√≥n de Hugging Face

```bash
# Login a Hugging Face (para acceso a Llama 3.2)
huggingface-cli login
# Ingresa tu token de HF Hub
```

### Configuraci√≥n de Weights & Biases (Opcional)

```bash
# Login a W&B para tracking de experimentos
wandb login
# Ingresa tu API key de W&B
```

## üéØ Uso del Framework

### 1. Entrenamiento Completo (Recomendado)

```bash
# Ejecutar pipeline completo: preparaci√≥n de datos + entrenamiento + evaluaci√≥n
python train_scm_legal.py --config config/scm_training_config.yaml --mode all
```

### 2. Pasos Individuales

```bash
# Solo preparaci√≥n de datos
python train_scm_legal.py --config config/scm_training_config.yaml --mode prepare

# Solo entrenamiento (requiere datos preparados)
python train_scm_legal.py --config config/scm_training_config.yaml --mode train

# Solo evaluaci√≥n (requiere modelo entrenado)
python train_scm_legal.py --config config/scm_training_config.yaml --mode evaluate
```

### 3. Configuraciones Espec√≠ficas

```bash
# Entrenamiento con GPU espec√≠fica
python train_scm_legal.py --config config/scm_training_config.yaml --gpu 0

# Modo debug con logs detallados
python train_scm_legal.py --config config/scm_training_config.yaml --debug

# Configuraci√≥n personalizada
python train_scm_legal.py --config config/my_custom_config.yaml --mode all
```

## üìä Configuraci√≥n del Entrenamiento

El archivo `config/scm_training_config.yaml` contiene todos los par√°metros configurables:

### Modelo Base
- **Llama 3.2 1B/3B**: Modelos base optimizados para concepto-nivel
- **Quantizaci√≥n 4-bit**: Reducci√≥n de memoria con QLoRA
- **LoRA**: Fine-tuning eficiente con par√°metros reducidos

### Datasets
- **Corpus Legal Multi-jurisdiccional**: Textos de Argentina, Chile, Uruguay, Espa√±a
- **Anotaci√≥n Autom√°tica**: Conceptos y cadenas de razonamiento
- **Augmentaci√≥n de Datos**: Parafraseo y sustituci√≥n conceptual

### Evaluaci√≥n
- **M√©tricas Acad√©micas**: Precisi√≥n conceptual, coherencia de razonamiento
- **Consistencia Multi-jurisdiccional**: Evaluaci√≥n cross-jurisdictional
- **Benchmarking**: Comparaci√≥n con modelos tradicionales

## üß† Componentes Principales

### 1. Extractor de Conceptos Legales (`concept_extractor.py`)

```python
from concept_extractor import LegalConceptExtractor

# Inicializar extractor
extractor = LegalConceptExtractor(config)

# Extraer conceptos de texto legal
texto = "El contrato de compraventa requiere consentimiento v√°lido..."
conceptos = extractor.extract_concepts(texto, jurisdiction='argentina')

for concepto in conceptos:
    print(f"Concepto: {concepto.concept_name}")
    print(f"Confianza: {concepto.confidence}")
```

### 2. Motor de Razonamiento (`concept_reasoner.py`)

```python
from concept_reasoner import ConceptualReasoningEngine, ReasoningType

# Inicializar motor de razonamiento
reasoner = ConceptualReasoningEngine(config)

# Realizar razonamiento deductivo
conceptos_iniciales = ['contrato_compraventa', 'vicios_consentimiento']
cadenas = reasoner.reason(
    initial_concepts=conceptos_iniciales,
    target_concept='contrato_nulo',
    jurisdiction='argentina',
    reasoning_type=ReasoningType.DEDUCTIVE
)

for cadena in cadenas:
    print(f"Conclusi√≥n: {cadena.final_conclusion}")
    print(f"Confianza: {cadena.overall_confidence}")
```

### 3. Evaluaci√≥n Especializada (`evaluation_metrics.py`)

```python
from evaluation_metrics import LegalEvaluationMetrics

# Inicializar evaluador
evaluator = LegalEvaluationMetrics(config)

# Evaluar muestras predichas vs ground truth
resultados = evaluator.evaluate_comprehensive(samples)

print(f"F1 Extracci√≥n de Conceptos: {resultados['concept_extraction_f1'].score}")
print(f"Coherencia de Razonamiento: {resultados['legal_reasoning_coherence'].score}")
```

## üìà Monitoreo y Resultados

### Weights & Biases Dashboard

Si tienes configurado W&B, puedes monitorear en tiempo real:

- **M√©tricas de Entrenamiento**: Loss, learning rate, gradient norms
- **Evaluaci√≥n**: Precisi√≥n conceptual, coherencia de razonamiento
- **Recursos**: Uso de GPU/memoria, tiempo de entrenamiento
- **Comparaciones**: M√∫ltiples experimentos y configuraciones

### Archivos de Resultados

Los resultados se guardan autom√°ticamente en:

```
results/
‚îú‚îÄ‚îÄ scm_legal_evaluation_20241127_143022.json    # Resultados detallados
‚îú‚îÄ‚îÄ scm_legal_final_report_20241127_143500.md    # Reporte final
‚îî‚îÄ‚îÄ corpus_statistics.json                       # Estad√≠sticas del corpus
```

### Logs de Entrenamiento

```
logs/
‚îî‚îÄ‚îÄ scm_legal_training_20241127_140000.log       # Log completo del proceso
```

## üéì Para Investigaci√≥n Acad√©mica

### Configuraciones Recomendadas para Papers

```yaml
# config/academic_paper_config.yaml
model:
  base_model: "meta-llama/Llama-3.2-3B"  # Modelo m√°s potente para resultados acad√©micos
  
training:
  num_train_epochs: 5                     # M√°s √©pocas para convergencia
  per_device_train_batch_size: 2          # Batch size para resultados consistentes
  learning_rate: 1e-4                     # LR conservativo
  
evaluation:
  metrics: ["concept_extraction_f1", "legal_reasoning_coherence", 
           "jurisdictional_consistency", "domain_accuracy"]
           
logging:
  use_wandb: true                         # Tracking completo para paper
  experiment_name: "SCM-Legal-Academic-v1"
```

### M√©tricas Clave para Publicaci√≥n

1. **Concept Extraction F1**: Precisi√≥n en identificaci√≥n de conceptos legales
2. **Legal Reasoning Coherence**: Calidad del razonamiento jur√≠dico generado
3. **Multi-jurisdictional Consistency**: Consistencia entre jurisdicciones
4. **Domain-specific Accuracy**: Precisi√≥n por √°rea legal espec√≠fica

### Benchmarking

El framework incluye comparaci√≥n autom√°tica con:
- **Modelos base sin fine-tuning**
- **Modelos fine-tuned tradicionales** (token-level)
- **Modelos legales existentes**

## üöÄ Implementaci√≥n de Producci√≥n

### Exportar Modelo Entrenado

```bash
# El modelo se guarda autom√°ticamente en formato HuggingFace
# Ubicaci√≥n: results/scm-legal-llama-3.2-1b/

# Para deployment, usar el modelo cuantizado
# Soporta ONNX, TensorRT, y formatos de edge computing
```

### Integraci√≥n con Cloudflare Workers

El modelo entrenado puede integrarse con la aplicaci√≥n web existente:

```typescript
// En src/routes/scm-legal.ts - reemplazar simulaci√≥n con modelo real
const realModel = await loadSCMModel('path/to/trained/model');
const conceptos = await realModel.extractConcepts(texto);
const razonamiento = await realModel.reason(conceptos);
```

## üêõ Troubleshooting

### Problemas Comunes

1. **Out of Memory (OOM)**
   ```bash
   # Reducir batch size en config
   per_device_train_batch_size: 1
   gradient_accumulation_steps: 16
   ```

2. **CUDA no disponible**
   ```bash
   # Verificar instalaci√≥n de PyTorch con CUDA
   python -c "import torch; print(torch.cuda.is_available())"
   ```

3. **Modelo Llama no accesible**
   ```bash
   # Verificar acceso a Llama 3.2 en HuggingFace
   huggingface-cli whoami
   ```

4. **Dependencias faltantes**
   ```bash
   # Reinstalar dependencias espec√≠ficas
   pip install transformers>=4.35.0 peft>=0.7.0
   ```

### Logs de Debug

```bash
# Ejecutar con logs detallados
python train_scm_legal.py --debug --config config/scm_training_config.yaml
```

## üìö Referencias Acad√©micas

Este framework implementa conceptos de:

- **Large Concept Models (LCMs)**: Fang et al. (2024)
- **Legal AI Reasoning**: Katz et al. (2023) 
- **Multi-jurisdictional Legal NLP**: Various legal NLP research
- **Parameter-Efficient Fine-tuning**: Hu et al. (2021) - LoRA

## ü§ù Contribuci√≥n

Para contribuir al proyecto acad√©mico:

1. Fork el repositorio
2. Crear branch para tu feature: `git checkout -b feature/nueva-metrica`
3. Commit cambios: `git commit -am 'A√±adir nueva m√©trica de evaluaci√≥n'`
4. Push al branch: `git push origin feature/nueva-metrica`
5. Crear Pull Request

## üìÑ Licencia

Este c√≥digo est√° disponible bajo licencia MIT para uso acad√©mico y de investigaci√≥n.

---

## üéØ Pr√≥ximos Pasos

Una vez completado el entrenamiento, los siguientes pasos para la investigaci√≥n acad√©mica:

1. **Validaci√≥n Experta**: Validaci√≥n de resultados con expertos legales
2. **Benchmarking Extenso**: Comparaci√≥n con m√°s modelos base
3. **An√°lisis Estad√≠stico**: Pruebas de significancia estad√≠stica
4. **Redacci√≥n del Paper**: Documentaci√≥n de metodolog√≠a y resultados
5. **C√≥digo Abierto**: Preparaci√≥n para release p√∫blico

Para m√°s informaci√≥n o asistencia, consultar la documentaci√≥n principal del proyecto o contactar al equipo de investigaci√≥n.